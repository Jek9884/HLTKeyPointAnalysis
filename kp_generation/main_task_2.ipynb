{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5d46e-0ff0-4fd3-9475-36f3695a4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from generative_model import GenerativeModel, train, test, validate\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from task2_utils import tokenize_df_gen, decode_data, compute_metrics, concat_tag\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, '../')\n",
    "import data_handler\n",
    "sys.path.insert(1, '../kp_match')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0833074-0a41-4a13-971b-3c7e336fff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f436461f-c497-483c-bcf4-4fd454287839",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a027e1-7afb-4ee3-8713-2cabf3b06d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = data_handler.load_full_dataset('../dataset/', get_train=True, get_dev=True, get_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7004097-3bfa-4a38-a00e-3e12f5689ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate topics and keypoints, as stated in the paper\n",
    "df_train = data_handler.concatenate_topics(df_train, input_col='argument', output_col='argument')\n",
    "df_val = data_handler.concatenate_topics(df_val, input_col='argument', output_col='argument')\n",
    "df_test = data_handler.concatenate_topics(df_test, input_col='argument', output_col='argument')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0958713-00c3-4a91-ad1e-72124f3191ef",
   "metadata": {},
   "source": [
    "# Compute baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be2cb13-5376-46ed-8f1b-9e4dd04f8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(model_type, device, loss, metrics):\n",
    "    \"\"\" Test baseline of model on validation and test set\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_type: string\n",
    "        name of model\n",
    "    device: torch device\n",
    "        Selected device on which to perform the grid search \n",
    "        (usually a GPU)\n",
    "    loss: function\n",
    "        function which computes model's loss\n",
    "    metrics: array-like\n",
    "        array of strings containing metrics\n",
    "        to compute\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Load model's tokenizer\n",
    "    if model_type == 'google/pegasus-large':\n",
    "        tokenizer = AutoTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "    \n",
    "    # Max length for tokenization\n",
    "    max_length = 100\n",
    "    \n",
    "    # Load data\n",
    "    _, df_val, df_test = data_handler.load_full_dataset('../dataset/', get_train=False, get_dev=True, get_test=True)\n",
    "\n",
    "    # Only take few test examples\n",
    "    df_test = df_test.sample(frac = 0.00027, random_state = 270898)\n",
    "    \n",
    "    # Concatenate topics and keypoints, as stated in the paper\n",
    "    df_val = data_handler.concatenate_topics(df_val, input_col='argument', output_col='argument')\n",
    "    df_test = data_handler.concatenate_topics(df_test, input_col='argument', output_col='argument')\n",
    "    \n",
    "    # Additional pre-processing step for t5 model\n",
    "    if model_type == \"t5-small\" or model_type == \"t5-base\" or model_type == \"t5-large\":\n",
    "        df_val = concat_tag(df_val, 'argument')\n",
    "        df_test = concat_tag(df_test, 'argument')\n",
    "    \n",
    "    # Istantiate model and move it on the desired device\n",
    "    model = GenerativeModel(model_type)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Tokenize data\n",
    "    tokenized_val = tokenize_df_gen(df_val, tokenizer, max_length=max_length)\n",
    "    tokenized_test = tokenize_df_gen(df_test, tokenizer, max_length=max_length, key_points_on=False)\n",
    "\n",
    "    # Organize data\n",
    "    seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True, max_length=max_length)\n",
    "    val_loader = DataLoader(\n",
    "        tokenized_val,\n",
    "        collate_fn=seq2seq_data_collator, \n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Validate model\n",
    "    val_res = validate(model, device, val_loader, max_length=max_length)\n",
    "    \n",
    "    dec_pred, dec_exp = decode_data(val_res['predicted'], val_res['labels'], tokenizer)\n",
    "    \n",
    "    # Compute metrics\n",
    "    val_metrics = compute_metrics(dec_pred, dec_exp, metrics)\n",
    "    print(f\"Validation results with model {model_type}:\")\n",
    "    print(val_metrics)\n",
    "    \n",
    "    # Pick some validation phrases to display\n",
    "    print(f\"Some validation phrases generated using {model_type}:\")\n",
    "    df_sample = df_val.sample(frac = 0.009, random_state = 270898)\n",
    "    index = df_sample.index\n",
    "    for i in index:\n",
    "        print(f\"Argument: {df_val['argument'].iloc[i]} \\nGenerated key-point: {dec_pred[i]}\\n\\n\")\n",
    "\n",
    "    print(\"----------------- TEST -----------------\")\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        tokenized_test, # dataset di validazione\n",
    "        collate_fn=seq2seq_data_collator, # data collator\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Test model\n",
    "    test_res = test(model, device, test_loader, max_length=max_length)\n",
    "\n",
    "    # Show test phrases\n",
    "    dec_pred = tokenizer.batch_decode(test_res['predicted'].type(torch.IntTensor).cpu().data.numpy(), skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"Some test phrases generated using {model_type}:\")\n",
    "    end = len(dec_pred)\n",
    "    for i in range(end):\n",
    "        print(f\"Argument: {df_test['argument'].iloc[i]} \\nGenerated key-point: {dec_pred[i]}\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbd8f9-05f9-4a30-b41a-ecf65a85fdae",
   "metadata": {},
   "source": [
    "# Pegasus Xsum baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d2ef34-e6f2-4fa2-af8b-19f03a6e14d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results with model google/pegasus-xsum:\n",
      "{'rouge': {'rouge1': {'precision': 0.06213652920676828, 'recall': 0.10197494484179298, 'fmeasure': 0.07226329623893364}, 'rouge2': {'precision': 0.005004212838704235, 'recall': 0.009373921670117321, 'fmeasure': 0.0061882023262247714}, 'rougeL': {'precision': 0.057589484741861985, 'recall': 0.09315528473137195, 'fmeasure': 0.06649627733578528}, 'rougeLsum': {'precision': 0.05764041082741468, 'recall': 0.09305865983855138, 'fmeasure': 0.06653920905986996}}}\n",
      "Some validation phrases generated using google/pegasus-xsum:\n",
      "Argument: The USA is a good country to live in It is an excellent country to live in due to its economy and possibilities of having a house, a car, a good job \n",
      "Generated key-point: What is your favourite country to live in?\n",
      "\n",
      "\n",
      "Argument: Routine child vaccinations should be mandatory They are against the freedom of parents to choose how to care for their children \n",
      "Generated key-point: Thousands of people have taken to the streets of London to protest against the government's decision to relax the rules on vaccinating children.\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in Excellent country and excellent people. I would not change it for anything \n",
      "Generated key-point: What would you change about the United States of America?\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in For something it is called the land of dreams where you must strive to achieve and live the American dream, land of freedom and free men where all men are equal. \n",
      "Generated key-point: The United States of America is the greatest country in the world.\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in The USA is a good country to live in because you have the freedom to elect government office and to live your life the way you want. \n",
      "Generated key-point: The USA is a good country to live in because you have the freedom to elect government office and to live your life the way you want.\n",
      "\n",
      "\n",
      "----------------- TEST -----------------\n",
      "Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: It is time for the UK to move away from a one-size-fits-all approach to family law.\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: As a father of two young children, I would like to see more support for dads who stay at home to raise their children.\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: algorithmic trading should be banned.\n",
      "\n",
      "\n",
      "Argument: We should subsidize embryonic stem cell research embryonic stem cell research is an unnatural act that goes against human decency.  the benefits do not justify the act. \n",
      "Generated key-point: The government should stop funding embryonic stem cell research.\n",
      "\n",
      "\n",
      "Argument: We should legalize polygamy polygamy should not be allowed as it demoralizes a woman in the since they they are not valued as the one and only woman that should be worshiped by a husband. \n",
      "Generated key-point: In our series of letters from African journalists, film-maker and columnist Farai Sevenzo considers polygamy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = 'google/pegasus-xsum'\n",
    "test_baseline(model_type, device, None, ['rouge']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2298a-90e0-49a1-bb29-3c941b198588",
   "metadata": {},
   "source": [
    "# T5 large baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc2c10f8-853b-40e7-b6cb-f7675aef5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results with model t5-large:\n",
      "{'rouge': {'rouge1': {'precision': 0.10961694906758337, 'recall': 0.295346156963005, 'fmeasure': 0.1545275636508756}, 'rouge2': {'precision': 0.034345113662356354, 'recall': 0.08198110766045547, 'fmeasure': 0.04687169373786172}, 'rougeL': {'precision': 0.10342556295835226, 'recall': 0.27779973649538947, 'fmeasure': 0.1456140366802304}, 'rougeLsum': {'precision': 0.10342266642318665, 'recall': 0.2771198004893661, 'fmeasure': 0.14555087425763585}}}\n",
      "Some validation phrases generated using t5-large:\n",
      "Argument: summarize: The USA is a good country to live in It is an excellent country to live in due to its economy and possibilities of having a house, a car, a good job \n",
      "Generated key-point: the usa is a good country to live in due to its economy and possibilities of having a house, a car, a good job. the\n",
      "\n",
      "\n",
      "Argument: summarize: Routine child vaccinations should be mandatory They are against the freedom of parents to choose how to care for their children \n",
      "Generated key-point: routine child vaccinations should be mandatory. they are against the freedom of parents to choose how to care for their children.\n",
      "\n",
      "\n",
      "Argument: summarize: The USA is a good country to live in Excellent country and excellent people. I would not change it for anything \n",
      "Generated key-point: the usa is a good country to live in excellent country and excellent people. the people are very friendly and helpful. the food is good and the people\n",
      "\n",
      "\n",
      "Argument: summarize: The USA is a good country to live in For something it is called the land of dreams where you must strive to achieve and live the American dream, land of freedom and free men where all men are equal. \n",
      "Generated key-point: the usa is a good country to live in. it is called the land of dreams. you must strive to achieve and live the american dream.\n",
      "\n",
      "\n",
      "Argument: summarize: The USA is a good country to live in The USA is a good country to live in because you have the freedom to elect government office and to live your life the way you want. \n",
      "Generated key-point: the usa is a good country to live in because you have the freedom to elect government office and to live your life the way you want.\n",
      "\n",
      "\n",
      "----------------- TEST -----------------\n",
      "Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: legalizing polygamy could cause many issues with marital benefits, such as health insurance.\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: stay-at-home dads are supported by a working mom who gets paid less than men. dads should be subsidized to make up the difference\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: algorithmic trading is a way to make money in a company. algorithmic trading works well when supply exceeds demand.\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize embryonic stem cell research embryonic stem cell research is an unnatural act that goes against human decency.  the benefits do not justify the act. \n",
      "Generated key-point: benefits do not justify the act. benefits are not a reason to subsidize research.\n",
      "\n",
      "\n",
      "Argument: summarize: We should legalize polygamy polygamy should not be allowed as it demoralizes a woman in the since they they are not valued as the one and only woman that should be worshiped by a husband. \n",
      "Generated key-point: polygamy should not be allowed as it demoralizes a woman. it makes her feel like she is not valued as the one and only woman \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = \"t5-large\"\n",
    "test_baseline(model_type, device, None, ['rouge']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9405b9-30c0-4827-869d-52c8e11a6512",
   "metadata": {},
   "source": [
    "# Pegasus large baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2939f0de-d713-49e2-8d51-0740796ada21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results with model google/pegasus-large:\n",
      "{'rouge': {'rouge1': {'precision': 0.10820963088972507, 'recall': 0.3143958999937265, 'fmeasure': 0.15573026472146867}, 'rouge2': {'precision': 0.03366233124541992, 'recall': 0.08740654474350124, 'fmeasure': 0.04722381748122127}, 'rougeL': {'precision': 0.10105335298347559, 'recall': 0.2929210257335261, 'fmeasure': 0.1451897431166692}, 'rougeLsum': {'precision': 0.10055656289123927, 'recall': 0.2912791867954916, 'fmeasure': 0.1448048784387525}}}\n",
      "Some validation phrases generated using google/pegasus-large:\n",
      "Argument: The USA is a good country to live in It is an excellent country to live in due to its economy and possibilities of having a house, a car, a good job \n",
      "Generated key-point: The USA is a good country to live in It is an excellent country to live in due to its economy and possibilities of having a house, a car, a good\n",
      "\n",
      "\n",
      "Argument: Routine child vaccinations should be mandatory They are against the freedom of parents to choose how to care for their children \n",
      "Generated key-point: Routine child vaccinations should be mandatory They are against the freedom of parents to choose how to care for their children\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in Excellent country and excellent people. I would not change it for anything \n",
      "Generated key-point: I would not change it for anything\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in For something it is called the land of dreams where you must strive to achieve and live the American dream, land of freedom and free men where all men are equal. \n",
      "Generated key-point: The USA is a good country to live in For something it is called the land of dreams where you must strive to achieve and live the American dream, land of freedom\n",
      "\n",
      "\n",
      "Argument: The USA is a good country to live in The USA is a good country to live in because you have the freedom to elect government office and to live your life the way you want. \n",
      "Generated key-point: The USA is a good country to live in The USA is a good country to live in because you have the freedom to elect government office and to live your life the\n",
      "\n",
      "\n",
      "----------------- TEST -----------------\n",
      "Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance.\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well.\n",
      "\n",
      "\n",
      "Argument: We should subsidize embryonic stem cell research embryonic stem cell research is an unnatural act that goes against human decency.  the benefits do not justify the act. \n",
      "Generated key-point: the benefits do not justify the act.\n",
      "\n",
      "\n",
      "Argument: We should legalize polygamy polygamy should not be allowed as it demoralizes a woman in the since they they are not valued as the one and only woman that should be worshiped by a husband. \n",
      "Generated key-point: We should legalize polygamy polygamy should not be allowed as it demoralizes a woman in the since they they are not valued as the one and only woman that should be\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = 'google/pegasus-large'\n",
    "test_baseline(model_type, device, None, ['rouge']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93415af1-02c9-495d-bd13-3163928d0bee",
   "metadata": {},
   "source": [
    "# Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e34f4a2-44e4-4b7a-9458-f529ea4981f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def show_time():\n",
    "    \"\"\" Displays current time\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd1b419-5fc5-48eb-8250-a8e04ac78b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(config, df_train, df_val, df_test, max_length, loss, metrics, device, save_val=\"\"):\n",
    "    \"\"\" Train model and evaluate it on\n",
    "    Validation and Test sets, computing\n",
    "    the metrics for each dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    config: dict\n",
    "        contains parameters and \n",
    "        hyper-parameters useful to train\n",
    "        the model\n",
    "    df_train: pd.DataFrame\n",
    "        Training data\n",
    "    df_val: pd.DataFrame\n",
    "        Validation Data\n",
    "    df_test: pd.DataFrame\n",
    "        Test Data\n",
    "    max_length: int\n",
    "        Max number of tokens\n",
    "    loss: function\n",
    "        function which computes model's loss\n",
    "    metrics: array-like\n",
    "        array of strings containing metrics\n",
    "        to compute\n",
    "    device: torch device\n",
    "        Selected device on which to perform the grid search \n",
    "        (usually a GPU)\n",
    "    save_val: string default=\"\"\n",
    "        if the string is not empty \n",
    "        the generated validation phrases will\n",
    "        be saved to the path contained in the string,\n",
    "        otherwise they won't be saved\n",
    "    Returns\n",
    "    -------\n",
    "    train_scores: array-like\n",
    "        Scores on the Training data of the challenge metrics \n",
    "    validation_scores: dict\n",
    "        Scores on the Validation data of the challenge metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the best model's tokenizer\n",
    "    if config['model_type'] == 'google/pegasus-large':\n",
    "        tokenizer = AutoTokenizer.from_pretrained('google/pegasus-xsum')\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config['model_type'])\n",
    "    \n",
    "    #Tokenize data\n",
    "    tokenized_tr = tokenize_df_gen(df_train, tokenizer, max_length=max_length)\n",
    "    tokenized_val = tokenize_df_gen(df_val, tokenizer, max_length=max_length)\n",
    "    tokenized_test = tokenize_df_gen(df_test, tokenizer, max_length=max_length, key_points_on=False)\n",
    "    \n",
    "    # Organize data\n",
    "    train_loader = DataLoader(tokenized_tr, batch_size = config['batch_size'], shuffle = True, pin_memory=True)\n",
    "    val_loader = DataLoader(tokenized_val, pin_memory=True)\n",
    "    test_loader = DataLoader(tokenized_test, pin_memory=True)\n",
    "\n",
    "    # Load model and move it on the desired device\n",
    "    model = GenerativeModel(config['model_type'])\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    \n",
    "    # Create optimizer and scheduler \n",
    "    if config['optimizer'] == 'adamW':\n",
    "        optimizer= torch.optim.AdamW(model.parameters(),\n",
    "                  lr = config['lr'], \n",
    "                  eps = config['eps'],\n",
    "                  weight_decay = config['weight_decay'])\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = config['warmup_steps'],\n",
    "                                        num_training_steps = total_steps)\n",
    "    \n",
    "    \n",
    "    print(\"Starting Training!\")\n",
    "    # Train best model\n",
    "    show_time()\n",
    "    train_res = train(model, device, train_loader, optimizer, config['epochs'], loss, scheduler, max_length, verbose=False)\n",
    "    print(\"Training ended!\")\n",
    "    show_time()\n",
    "    \n",
    "    # Compute metrics\n",
    "    train_scores = [None] * len(train_res['predicted'])\n",
    "    for i, elem in enumerate(train_res['predicted']):\n",
    "        dec_pred, dec_exp = decode_data(elem, train_res['labels'][i], tokenizer)\n",
    "        train_scores[i] = compute_metrics(dec_pred, dec_exp, metrics)\n",
    "    \n",
    "    print(\"Train performances\")\n",
    "    print(train_scores)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Perform evaluation\n",
    "    val_res = validate(model, device, val_loader, max_length=max_length)\n",
    "    \n",
    "    # Compute metrics\n",
    "    dec_pred, dec_exp = decode_data(val_res['predicted'], val_res['labels'], tokenizer)\n",
    "    validation_scores = compute_metrics(dec_pred, dec_exp, metrics)\n",
    "    \n",
    "    print(\"Validation performances\")\n",
    "    print(validation_scores)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Save generated validation phrases\n",
    "    if save_val != \"\":\n",
    "        df = pd.DataFrame()\n",
    "        df['predictions'] = dec_pred\n",
    "        df['expected'] = dec_exp\n",
    "        df.to_csv(save_val, sep='#')\n",
    "    \n",
    "    # Perform evaluation\n",
    "    test_res = test(model, device, test_loader, max_length=max_length)\n",
    "    \n",
    "    # Print test generated phrases\n",
    "    dec_pred = tokenizer.batch_decode(test_res['predicted'].type(torch.IntTensor).cpu().data.numpy(), skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"# Some test phrases generated using {config['model_type']}:\")\n",
    "    end = len(dec_pred)\n",
    "    for i in range(end):\n",
    "        print(f\"Argument: {df_test['argument'].iloc[i]} \\nGenerated key-point: {dec_pred[i]}\\n\\n\")\n",
    "        \n",
    "    return train_scores, validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7dfc902-d06e-4224-8757-cd28eb12e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_var(res, set_name):\n",
    "    \"\"\" Compute and print mean and variance of the computed scores\n",
    "    Parameters\n",
    "    ----------\n",
    "    res: array-like\n",
    "        array containing the scores\n",
    "    set_name: string\n",
    "        name of set of data\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    # Extract values of elements in the array correctly, depending on their shape\n",
    "    for el in res:\n",
    "            if len(el) >= 2:\n",
    "                el = el[-1]\n",
    "            if type(el) == dict:\n",
    "                arr.append(el['rouge']['rouge1']['fmeasure'])\n",
    "            else: \n",
    "                arr.append(el[0]['rouge']['rouge1']['fmeasure'])\n",
    "    \n",
    "    arr = np.array(arr)\n",
    "    \n",
    "    # Array of single values to compute mean and variance on\n",
    "    vals = []\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        vals.append(arr[i])\n",
    "\n",
    "    vals = np.array(vals)\n",
    "    print(f\"{set_name} Mean: {vals.mean()} and Variance: {vals.var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89fb19-65d2-44ab-b706-902fbd3bd8e8",
   "metadata": {},
   "source": [
    "### Pegasus base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ac2c11-b67b-4e20-8f6b-4e10a2d8fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['model_type'] = 'google/pegasus-xsum'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 4e-4\n",
    "config['eps'] = 1e-6\n",
    "config['weight_decay'] = 1e-8\n",
    "config['warmup_steps'] = 1e2\n",
    "config['batch_size'] = 8\n",
    "config['optimizer'] = 'adamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a63002-b0c8-4bbe-ac28-9450763a53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac = 0.00018, random_state = 270898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c94a94a-c4b4-4a60-b3dc-e34d205fa070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 14:35:53\n",
      "Training ended!\n",
      "Current Time = 14:53:07\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.30724058780341995, 'recall': 0.3620097093949123, 'fmeasure': 0.31785761313826877}, 'rouge2': {'precision': 0.2083250475335769, 'recall': 0.2514903167492144, 'fmeasure': 0.21942628878586368}, 'rougeL': {'precision': 0.3007181961678671, 'recall': 0.35445767148573204, 'fmeasure': 0.31116840764530984}, 'rougeLsum': {'precision': 0.3004019915214863, 'recall': 0.35429599037417026, 'fmeasure': 0.31093671758658303}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.1591784435134822, 'recall': 0.18309427086601043, 'fmeasure': 0.1642876361800807}, 'rouge2': {'precision': 0.023830675664914786, 'recall': 0.025459368530020697, 'fmeasure': 0.023746484694542977}, 'rougeL': {'precision': 0.13371991134339328, 'recall': 0.14885487901792285, 'fmeasure': 0.1357002470673943}, 'rougeLsum': {'precision': 0.13366777713205188, 'recall': 0.14852742617688303, 'fmeasure': 0.13543312840974758}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: A polygamous marriage is expensive\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: A stay-at-home dads are better off financially than other workers\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: algorithmic trading increases liquidity\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 14:56:34\n",
      "Training ended!\n",
      "Current Time = 15:13:35\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.2973195574290777, 'recall': 0.35283948522243747, 'fmeasure': 0.30938704482303714}, 'rouge2': {'precision': 0.19922198537480684, 'recall': 0.24195774280734755, 'fmeasure': 0.21093381274823186}, 'rougeL': {'precision': 0.29005290712055304, 'recall': 0.34447772643300767, 'fmeasure': 0.30198617522966187}, 'rougeLsum': {'precision': 0.28987647284597556, 'recall': 0.3441524685409732, 'fmeasure': 0.3019047814933153}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.15881229603256503, 'recall': 0.18272554739946067, 'fmeasure': 0.1633322356056729}, 'rouge2': {'precision': 0.03150660103785103, 'recall': 0.03845252472969862, 'fmeasure': 0.03299489143710269}, 'rougeL': {'precision': 0.14006268460392562, 'recall': 0.16077274426459234, 'fmeasure': 0.14370104694235686}, 'rougeLsum': {'precision': 0.13966148659642952, 'recall': 0.16023014827362686, 'fmeasure': 0.14333336884210754}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: Polygamy is not fair/discriminatory\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: Stay-at-home dads are better off financially than those who choose to stay at home\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: A ban on algorithmic trading increases liquidity\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 15:17:06\n",
      "Training ended!\n",
      "Current Time = 15:34:14\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.3140216682723942, 'recall': 0.3630071071885289, 'fmeasure': 0.3224466158338626}, 'rouge2': {'precision': 0.21002472132879033, 'recall': 0.25134273244664435, 'fmeasure': 0.2200890216021645}, 'rougeL': {'precision': 0.3069540797300022, 'recall': 0.3551965526192703, 'fmeasure': 0.31542366816184875}, 'rougeLsum': {'precision': 0.30647677892541547, 'recall': 0.35455381369997147, 'fmeasure': 0.31501810404753916}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.15764480255169244, 'recall': 0.1954161176987266, 'fmeasure': 0.16912481519762745}, 'rouge2': {'precision': 0.03590384052340574, 'recall': 0.04125690131124912, 'fmeasure': 0.037134956856445245}, 'rougeL': {'precision': 0.13399172055861683, 'recall': 0.16489565687935281, 'fmeasure': 0.14326883780071892}, 'rougeLsum': {'precision': 0.1336151053082803, 'recall': 0.1642113748771361, 'fmeasure': 0.14287498299257606}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: Polygamous relationships are unstable\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: A stay-at-home dads are losing their childhood\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: algorithmic trading increases liquidity\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 15:38:08\n",
      "Training ended!\n",
      "Current Time = 15:55:43\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.3148398310959848, 'recall': 0.37501928774062454, 'fmeasure': 0.32753399067453304}, 'rouge2': {'precision': 0.2142674713642125, 'recall': 0.26110789756409797, 'fmeasure': 0.22660305153188487}, 'rougeL': {'precision': 0.30761881265649554, 'recall': 0.3663600992344975, 'fmeasure': 0.32022263709540255}, 'rougeLsum': {'precision': 0.3076139229748137, 'recall': 0.36632610808781196, 'fmeasure': 0.32006830701840006}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.14907746728756482, 'recall': 0.16150300233180703, 'fmeasure': 0.14826142385070756}, 'rouge2': {'precision': 0.020573521184934225, 'recall': 0.023989964343225208, 'fmeasure': 0.020908866992626576}, 'rougeL': {'precision': 0.13626772189057695, 'recall': 0.14689333160800594, 'fmeasure': 0.13521098648545204}, 'rougeLsum': {'precision': 0.1364842055774553, 'recall': 0.14694643118556197, 'fmeasure': 0.13546512243995196}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: Polygamies are expensive\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: A stay-at-home dads are better off financially than their counterparts\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: A ban on algorithmic trading reduces the risk of losing money\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 15:59:44\n",
      "Training ended!\n",
      "Current Time = 16:17:01\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.2895513451788633, 'recall': 0.34716338083684883, 'fmeasure': 0.3025327840011779}, 'rouge2': {'precision': 0.1882447539977598, 'recall': 0.23333321930040005, 'fmeasure': 0.20059316146805917}, 'rougeL': {'precision': 0.28165821135200153, 'recall': 0.33800766254997905, 'fmeasure': 0.2944474869107111}, 'rougeLsum': {'precision': 0.2814118863187842, 'recall': 0.3377884635650232, 'fmeasure': 0.29427455849999046}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.14882068858251762, 'recall': 0.17592697157914589, 'fmeasure': 0.15557871112374982}, 'rouge2': {'precision': 0.022649741060067133, 'recall': 0.02602728893489762, 'fmeasure': 0.023162586945355473}, 'rougeL': {'precision': 0.12611235294259632, 'recall': 0.14738338352468822, 'fmeasure': 0.13055497664602472}, 'rougeLsum': {'precision': 0.12568851133828796, 'recall': 0.14708243145743183, 'fmeasure': 0.13031988727075255}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-xsum:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: A polygamy harms the family\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: A stay-at-home dads are losing their childhood\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: A ban on algorithmic trading is beneficial for the entire market/society\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_metrics = []; val_metrics = [];\n",
    "save_res = \"\"\n",
    "for i in range(5):\n",
    "    if i == 4:\n",
    "        save_res = 'pegasus_val.csv'\n",
    "    tr, val = train_best_model(config, df_train, df_val, df_test, 100, None, ['rouge'], device, save_res)\n",
    "    tr_metrics.append(tr)\n",
    "    val_metrics.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b6bb042-af6a-4ff9-8c5d-c3051aa2edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.31595160969417585 and Variance: 8.062557959681058e-05\n",
      "Validation Mean: 0.1601169643915677 and Variance: 5.400468650616418e-05\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18541340-3892-4228-82fa-67290578db39",
   "metadata": {},
   "source": [
    "### T5 Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8eb20a3-c70c-4728-87b6-eefe6b47dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['model_type'] = 't5-large'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 2e-5\n",
    "config['eps'] = 1e-8\n",
    "config['weight_decay'] = 0\n",
    "config['warmup_steps'] = 1e2\n",
    "config['batch_size'] = 4\n",
    "config['optimizer'] = 'adamW'\n",
    "\n",
    "\n",
    "#Only for T5\n",
    "df_tr = df_train\n",
    "df_v = df_val\n",
    "df_te = df_test\n",
    "df_tr = concat_tag(df_tr, 'argument')\n",
    "df_v = concat_tag(df_v, 'argument')\n",
    "df_te = concat_tag(df_te, 'argument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce08481-4d5b-4294-8140-c361624ba9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.sample(frac = 0.00018, random_state = 270898)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45765267-e5c5-42ef-809e-4e27c09eb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 17:55:30\n",
      "Training ended!\n",
      "Current Time = 18:40:15\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.13039234806901873, 'recall': 0.2772629269643505, 'fmeasure': 0.16647823191251548}, 'rouge2': {'precision': 0.04069219795437884, 'recall': 0.09150309764297974, 'fmeasure': 0.052229193176196106}, 'rougeL': {'precision': 0.12093662889182433, 'recall': 0.2586256273467172, 'fmeasure': 0.1545348879978713}, 'rougeLsum': {'precision': 0.12096531020286447, 'recall': 0.2586143470270639, 'fmeasure': 0.15460781518492983}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.1387286630127928, 'recall': 0.2662663448668885, 'fmeasure': 0.17147911701220686}, 'rouge2': {'precision': 0.044379200193840965, 'recall': 0.07188973717506326, 'fmeasure': 0.051012310368146185}, 'rougeL': {'precision': 0.13318115725233315, 'recall': 0.2531902879728971, 'fmeasure': 0.1639344075837387}, 'rougeLsum': {'precision': 0.13250231357363396, 'recall': 0.2522886408076629, 'fmeasure': 0.16325809339026304}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: we should legalize polygamy because it could lead to health benefits and other benefits.\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: we should subsidize stay-at-home dads because they are being supported by a working mom.\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: we should ban algorithmic trading because it can lead to oversupply. algorithmic trading can be used to increase profits if the supply exceeds demand.\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 18:50:39\n",
      "Training ended!\n",
      "Current Time = 19:35:03\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.13748414009541923, 'recall': 0.268388101936888, 'fmeasure': 0.16946460226706833}, 'rouge2': {'precision': 0.04345765939535441, 'recall': 0.08865864675416411, 'fmeasure': 0.05336207245961464}, 'rougeL': {'precision': 0.12875698981678013, 'recall': 0.25204059519278155, 'fmeasure': 0.15871896801350482}, 'rougeLsum': {'precision': 0.12886682025670734, 'recall': 0.25217218988337586, 'fmeasure': 0.15886341557770023}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.14216426397518817, 'recall': 0.27354726091139203, 'fmeasure': 0.17558152699512697}, 'rouge2': {'precision': 0.04770153904142456, 'recall': 0.07604597998619739, 'fmeasure': 0.05351420686862265}, 'rougeL': {'precision': 0.13529739487843556, 'recall': 0.2593201032059732, 'fmeasure': 0.16669760770293202}, 'rougeLsum': {'precision': 0.1353593413975636, 'recall': 0.25897768445322844, 'fmeasure': 0.16656763505075362}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: legalizing polygamy could cause problems with health insurance\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: we should subsidize stay-at-home dads because they are being supported by a working mom.\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: algorithmic trading can help companies when supply exceeds demand. algorithmic trading can help companies when supply exceeds demand.\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 19:56:39\n",
      "Training ended!\n",
      "Current Time = 20:41:03\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.13039234806901873, 'recall': 0.2772629269643505, 'fmeasure': 0.16647823191251548}, 'rouge2': {'precision': 0.04069219795437884, 'recall': 0.09150309764297974, 'fmeasure': 0.052229193176196106}, 'rougeL': {'precision': 0.12093662889182433, 'recall': 0.2586256273467172, 'fmeasure': 0.1545348879978713}, 'rougeLsum': {'precision': 0.12096531020286447, 'recall': 0.2586143470270639, 'fmeasure': 0.15460781518492983}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.1387286630127928, 'recall': 0.2662663448668885, 'fmeasure': 0.17147911701220686}, 'rouge2': {'precision': 0.044379200193840965, 'recall': 0.07188973717506326, 'fmeasure': 0.051012310368146185}, 'rougeL': {'precision': 0.13318115725233315, 'recall': 0.2531902879728971, 'fmeasure': 0.1639344075837387}, 'rougeLsum': {'precision': 0.13250231357363396, 'recall': 0.2522886408076629, 'fmeasure': 0.16325809339026304}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: we should legalize polygamy because it could lead to health benefits and other benefits.\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: we should subsidize stay-at-home dads because they are being supported by a working mom.\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: we should ban algorithmic trading because it can lead to oversupply. algorithmic trading can be used to increase profits if the supply exceeds demand.\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 20:51:40\n",
      "Training ended!\n",
      "Current Time = 21:36:13\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.12989789625201847, 'recall': 0.2733998227750861, 'fmeasure': 0.16511353720021096}, 'rouge2': {'precision': 0.040563884200504274, 'recall': 0.0907922455855598, 'fmeasure': 0.05153684119214737}, 'rougeL': {'precision': 0.121538881211719, 'recall': 0.2568573266802542, 'fmeasure': 0.15441621646782722}, 'rougeLsum': {'precision': 0.12154850480139069, 'recall': 0.25693853797779104, 'fmeasure': 0.1544352231071728}}}]  \n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.13168670614349628, 'recall': 0.27621089910492125, 'fmeasure': 0.1692755539531995}, 'rouge2': {'precision': 0.03959403874010933, 'recall': 0.07352592305037961, 'fmeasure': 0.0486561358996086}, 'rougeL': {'precision': 0.12484830973310312, 'recall': 0.2617173939184813, 'fmeasure': 0.1602299112832467}, 'rougeLsum': {'precision': 0.12490648353362309, 'recall': 0.26190178832841937, 'fmeasure': 0.16034539184096522}}} \n",
      "\n",
      "\n",
      "# Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance.\n",
      "Generated key-point: we should legalize polygamy because it could cause problems with health insurance.\n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference.\n",
      "Generated key-point: stay-at-home dads are being supported by a working mom. we should subsidize stay-at-home dads to make up the difference\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well.\n",
      "Generated key-point: algorithmic trading can help companies when supply exceeds demand. we should ban algorithmic trading because it can help companies manage risk.\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 21:46:02\n",
      "Training ended!\n",
      "Current Time = 22:31:56\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.13329086541855678, 'recall': 0.2543355107463832, 'fmeasure': 0.16310691034752187}, 'rouge2': {'precision': 0.04143668481162935, 'recall': 0.08044237560779435, 'fmeasure': 0.05012167869516546}, 'rougeL': {'precision': 0.1252878906614101, 'recall': 0.2394480932631474, 'fmeasure': 0.15331637841716422}, 'rougeLsum': {'precision': 0.1251735129641388, 'recall': 0.23934441390968006, 'fmeasure': 0.1531506383839996}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.13936194475346858, 'recall': 0.2649861712361715, 'fmeasure': 0.17134467798177125}, 'rouge2': {'precision': 0.04727043237447384, 'recall': 0.07321859903381642, 'fmeasure': 0.052281889139173005}, 'rougeL': {'precision': 0.13258316535929573, 'recall': 0.25135631025576743, 'fmeasure': 0.16287773221297466}, 'rougeLsum': {'precision': 0.13284180751858732, 'recall': 0.25149982616015265, 'fmeasure': 0.16324016625989843}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using t5-large:\n",
      "Argument: summarize: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance.\n",
      "Generated key-point: we should legalize polygamy because it could cause problems with health insurance \n",
      "\n",
      "\n",
      "Argument: summarize: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference.\n",
      "Generated key-point: we should subsidize stay-at-home dads, says sarah saunders. dads are being supported by a working mom\n",
      "\n",
      "\n",
      "Argument: summarize: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: we should ban algorithmic trading because it can be used to increase profits.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_metrics = []; val_metrics = [];\n",
    "save_res = \"\"\n",
    "for i in range(5):\n",
    "    if i == 4:\n",
    "        save_res = 't5_large_val.csv'\n",
    "    tr, val = train_best_model(config, df_train, df_val, df_test, 100, None, ['rouge'], device, save_res)\n",
    "    tr_metrics.append(tr)\n",
    "    val_metrics.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b9e50a3-8361-42ba-af1f-c2685ce6da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.16612830272796644 and Variance: 4.306871295187838e-06\n",
      "Validation Mean: 0.17183199859090229 and Variance: 4.216180926595218e-06\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c7f65-1ad1-4c1c-9c2c-93f41a15f5b0",
   "metadata": {},
   "source": [
    "### Pegasus Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e41619f-25fb-4439-a765-c130ef98ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['model_type'] = 'google/pegasus-large'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 5e-4\n",
    "config['eps'] = 1e-8\n",
    "config['weight_decay'] = 1e-6\n",
    "config['warmup_steps'] = 1e3\n",
    "config['batch_size'] = 8\n",
    "config['optimizer'] = 'adamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffff8d2-4486-4879-98aa-72bb124e2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 20:59:19\n",
      "Training ended!\n",
      "Current Time = 21:16:59\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.18183926160919697, 'recall': 0.23309780080863485, 'fmeasure': 0.18514979968414852}, 'rouge2': {'precision': 0.09583374205499902, 'recall': 0.12766603652619835, 'fmeasure': 0.10276293387582418}, 'rougeL': {'precision': 0.1755627003410492, 'recall': 0.2241461695955993, 'fmeasure': 0.1784404415138791}, 'rougeLsum': {'precision': 0.17570379543193, 'recall': 0.22407952524999306, 'fmeasure': 0.17848723751034817}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.15293951054052973, 'recall': 0.18594011413304923, 'fmeasure': 0.15968759432984228}, 'rouge2': {'precision': 0.03507326887082321, 'recall': 0.03795505521048996, 'fmeasure': 0.03378925066987077}, 'rougeL': {'precision': 0.14019070757160124, 'recall': 0.16872666886253876, 'fmeasure': 0.14533371129964887}, 'rougeLsum': {'precision': 0.14031292677792073, 'recall': 0.16879261036869775, 'fmeasure': 0.1453957364875426}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: should be legalized polygamy harms the state's image/reputation\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: subsidizing a stay-at-at-home dads increases the quality of life for women\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: Algorithm trading is necessary for the benefit of the entire market/society\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 21:20:40\n",
      "Training ended!\n",
      "Current Time = 21:38:20\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.18510413443310408, 'recall': 0.23640974052513627, 'fmeasure': 0.1874445937982357}, 'rouge2': {'precision': 0.09835691859330975, 'recall': 0.1310618187485112, 'fmeasure': 0.10395620227664207}, 'rougeL': {'precision': 0.1787781061961154, 'recall': 0.22671536604984932, 'fmeasure': 0.18063726881683256}, 'rougeLsum': {'precision': 0.17870122918378598, 'recall': 0.22692752175795358, 'fmeasure': 0.18069123502159357}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.11692135794979532, 'recall': 0.1314809586548718, 'fmeasure': 0.11751538843289848}, 'rouge2': {'precision': 0.028051278934431087, 'recall': 0.02463444616977225, 'fmeasure': 0.02456534462251079}, 'rougeL': {'precision': 0.10078720217986539, 'recall': 0.1139062728736643, 'fmeasure': 0.10150132489404598}, 'rougeLsum': {'precision': 0.10089451355422002, 'recall': 0.11407952454148107, 'fmeasure': 0.1017240637909035}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: We should not legalize polygamy\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: STAY-at-home dads should be able to supplement their income if they choose to\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: is necessary to reduce institutional trading\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 21:42:12\n",
      "Training ended!\n",
      "Current Time = 22:00:34\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.18309926158469936, 'recall': 0.24134464114205953, 'fmeasure': 0.18848620506896696}, 'rouge2': {'precision': 0.09918096821546932, 'recall': 0.1346338708676292, 'fmeasure': 0.10595420253611523}, 'rougeL': {'precision': 0.17697074033262156, 'recall': 0.2319551109654645, 'fmeasure': 0.18156240017773878}, 'rougeLsum': {'precision': 0.1770116755246171, 'recall': 0.2319086607614513, 'fmeasure': 0.18174934552323363}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.16288113180096908, 'recall': 0.16389950880440038, 'fmeasure': 0.15706803737613184}, 'rouge2': {'precision': 0.04960640959282262, 'recall': 0.04964666724177588, 'fmeasure': 0.047548077455366405}, 'rougeL': {'precision': 0.15883759457129054, 'recall': 0.15900418522701154, 'fmeasure': 0.15283836285827268}, 'rougeLsum': {'precision': 0.15906541500970892, 'recall': 0.15959112344981935, 'fmeasure': 0.15309090157875177}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: can lead to wrong sexual behaviour\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: are necessary to compensate for the quality of life that a father should be able to provide\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: can be used to reduce latency\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 22:03:59\n",
      "Training ended!\n",
      "Current Time = 22:21:41\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.17894832452842915, 'recall': 0.2415577683509853, 'fmeasure': 0.18759893458410729}, 'rouge2': {'precision': 0.0967876618044489, 'recall': 0.13768094908462825, 'fmeasure': 0.1060432073793704}, 'rougeL': {'precision': 0.17375936055177627, 'recall': 0.23312981272540095, 'fmeasure': 0.18177146559009683}, 'rougeLsum': {'precision': 0.1738263711906479, 'recall': 0.23335475521099747, 'fmeasure': 0.1818442425086761}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.12397624804085666, 'recall': 0.15997886473429979, 'fmeasure': 0.13514621176187838}, 'rouge2': {'precision': 0.023178002050284648, 'recall': 0.027017195767195763, 'fmeasure': 0.02397153652622086}, 'rougeL': {'precision': 0.11367769160638375, 'recall': 0.14645552967563857, 'fmeasure': 0.12363850554563224}, 'rougeLsum': {'precision': 0.11387422615074438, 'recall': 0.1467026959554137, 'fmeasure': 0.1239037553682864}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: benefits are important to a polygamous relationship\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: encourage the child's education\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: should not be banned as long as there is continuous improvement\n",
      "\n",
      "\n",
      "Starting Training!\n",
      "Current Time = 22:26:03\n",
      "Training ended!\n",
      "Current Time = 22:44:03\n",
      "Train performances\n",
      "[{'rouge': {'rouge1': {'precision': 0.16804465748257386, 'recall': 0.23836808005475424, 'fmeasure': 0.1761834751559399}, 'rouge2': {'precision': 0.08233024912867695, 'recall': 0.1264420892285273, 'fmeasure': 0.09127849522575135}, 'rougeL': {'precision': 0.16263128806083246, 'recall': 0.2286922246143436, 'fmeasure': 0.1698881418082651}, 'rougeLsum': {'precision': 0.1626527796427129, 'recall': 0.2288902127062387, 'fmeasure': 0.1698691131103542}}}]\n",
      "\n",
      "\n",
      "Validation performances\n",
      "{'rouge': {'rouge1': {'precision': 0.1324116600856198, 'recall': 0.14873188405797114, 'fmeasure': 0.1345840905162157}, 'rouge2': {'precision': 0.03298003702215657, 'recall': 0.030639665286404417, 'fmeasure': 0.030393216452869194}, 'rougeL': {'precision': 0.12734674225316925, 'recall': 0.14184766270364124, 'fmeasure': 0.12878645462734362}, 'rougeLsum': {'precision': 0.12729427292120832, 'recall': 0.14218158552397694, 'fmeasure': 0.12885735050331099}}}\n",
      "\n",
      "\n",
      "# Some test phrases generated using google/pegasus-large:\n",
      "Argument: We should legalize polygamy polygamy, if legalized, could cause many issues with marital benefits, such as health insurance. \n",
      "Generated key-point: Affirmative action is necessary to compensate for the harms that have been done to the family\n",
      "\n",
      "\n",
      "Argument: We should subsidize stay-at-home dads When dads stay at home, they are being supported by a working mom who gets paid less than men, so the father should be subsidized to make up the difference. \n",
      "Generated key-point: offer a better compensate for the child's education\n",
      "\n",
      "\n",
      "Argument: We should ban algorithmic trading sometimes in a company the supply exceeds the demand so this process would work well. \n",
      "Generated key-point: is is necessary to reduce the risk of inserting bias/harming the market\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_metrics = []; val_metrics = [];\n",
    "save_res = \"\"\n",
    "for i in range(5):\n",
    "    if i == 4:\n",
    "        save_res = 'pegasus_large_val.csv'\n",
    "    tr, val = train_best_model(config, df_train, df_val, df_test, 100, None, ['rouge'], device, save_res)\n",
    "    tr_metrics.append(tr)\n",
    "    val_metrics.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24be24cc-cac7-47b1-a4f8-431e6605b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.18497260165827967 and Variance: 2.05267845038774e-05\n",
      "Validation Mean: 0.14080026448339333 and Variance: 0.0002468332494546151\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics, set_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
