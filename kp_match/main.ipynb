{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from challenge_metrics import load_kpm_data\n",
    "from siamese_network import SiameseNetwork, train, test\n",
    "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from matching_utils import compute_metrics, extract_challenge_metrics\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "import data_handler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device = torch.device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ֿ** loading task data:\n",
      "\n",
      "ֿ** loading task data:\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "_, df_val, df_test = data_handler.load(path=\"../dataset/\", filename_test=\"test.csv\", filename_dev=\"dev.csv\", sep_char='#')\n",
    "val_kpm_data = load_kpm_data(\"../dataset/\", subset=\"dev\")\n",
    "test_kpm_data = load_kpm_data(\"../dataset/\", subset=\"test\")\n",
    "\n",
    "# Concatenate topics and keypoints, as stated in the paper\n",
    "df_test = data_handler.concatenate_topics(df_test)\n",
    "df_val = data_handler.concatenate_topics(df_val)\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(model_type, device, loss, df_val, df_test, val_kpm_data, test_kpm_data, metrics):\n",
    "    \"\"\" Test baseline of model on validation and test set\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_type: string\n",
    "        name of model\n",
    "    device: torch device\n",
    "        Selected device on which to perform the grid search \n",
    "        (usually a GPU)\n",
    "    loss: function\n",
    "        function which computes model's loss\n",
    "    df_val: pd.DataFrame\n",
    "        Validation Data\n",
    "    df_test: pd.DataFrame\n",
    "        Test Data\n",
    "    val_kpm_data: tuple\n",
    "        Validation data from challenge\n",
    "    test_kpm_data: tuple\n",
    "        Test data from challenge\n",
    "    metrics: array-like\n",
    "        array of strings containing metrics\n",
    "        to compute\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load our model's (bert-base-uncased) tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_type, do_lower_case=True)\n",
    "\n",
    "    #Tokenize data\n",
    "    columns_list = ['argument', 'key_points', 'label']\n",
    "    tokenized_test = data_handler.tokenize_df(df_test[columns_list], tokenizer, max_length=max_length)\n",
    "    tokenized_val = data_handler.tokenize_df(df_val[columns_list], tokenizer, max_length=max_length)\n",
    "\n",
    "    test_loader = DataLoader(tokenized_test, pin_memory=True)\n",
    "    val_loader = DataLoader(tokenized_val, pin_memory=True)\n",
    "    \n",
    "    # Load model and move it on the desired device\n",
    "    model = SiameseNetwork(model_type=AutoModel.from_pretrained(model_type))\n",
    "    model.to(device)\n",
    "    print(\"Model successfully loaded!\\n\")\n",
    "    \n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    val_res = test(model, device, val_loader, loss)\n",
    "\n",
    "    # Compute metrics\n",
    "    val_metrics = compute_metrics(val_res['predicted'].T, val_res['labels'].T, metrics)\n",
    "    print(f\"Validation results with model {model_type}:\")\n",
    "    print(val_metrics)\n",
    "\n",
    "    # Compute challenge metrics\n",
    "    val_challenge_metrics = extract_challenge_metrics(val_res['predicted'].T, val_kpm_data[2], val_kpm_data[0], val_kpm_data[1])\n",
    "    print(val_challenge_metrics)\n",
    "    \n",
    "    test_res = test(model, device, test_loader, loss)\n",
    "\n",
    "    # Compute metrics\n",
    "    test_metrics = compute_metrics(test_res['predicted'].T, test_res['labels'].T, metrics)\n",
    "    print(f\"Test results with model {model_type}:\")\n",
    "    print(test_metrics)\n",
    "\n",
    "    # Compute challenge metrics\n",
    "    test_challenge_metrics = extract_challenge_metrics(test_res['predicted'].T, test_kpm_data[2], test_kpm_data[0], test_kpm_data[1])\n",
    "    print(test_challenge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded!\n",
      "\n",
      "Validation results with model bert-base-uncased:\n",
      "{'accuracy': 0.21341816078658185, 'precision': 0.21341816078658185, 'recall': 1.0, 'f1': 0.3517635843660629}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.2299602651825317 ; mAP relaxed = 0.2299602651825317\n",
      "(0.2299602651825317, 0.2299602651825317)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.16112084063047286, 'precision': 0.16112084063047286, 'recall': 1.0, 'f1': 0.27752639517345395}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.15331714855933892 ; mAP relaxed = 0.15331714855933892\n",
      "(0.15331714855933892, 0.15331714855933892)\n"
     ]
    }
   ],
   "source": [
    "test_baseline('bert-base-uncased', device, loss, df_val, df_test, val_kpm_data, test_kpm_data, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa-base baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded!\n",
      "\n",
      "Validation results with model roberta-base:\n",
      "{'accuracy': 0.21341816078658185, 'precision': 0.21341816078658185, 'recall': 1.0, 'f1': 0.3517635843660629}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.12368955349553747 ; mAP relaxed = 0.12368955349553747\n",
      "None\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.16112084063047286, 'precision': 0.16112084063047286, 'recall': 1.0, 'f1': 0.27752639517345395}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.059267577712564024 ; mAP relaxed = 0.059267577712564024\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_baseline('roberta-base', device, loss, df_val, df_test, val_kpm_data, test_kpm_data, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa-Large baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded!\n",
      "\n",
      "Validation results with model roberta-large:\n",
      "{'accuracy': 0.21341816078658185, 'precision': 0.21341816078658185, 'recall': 1.0, 'f1': 0.3517635843660629}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.07408259804980344 ; mAP relaxed = 0.07408259804980344\n",
      "None\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.16112084063047286, 'precision': 0.16112084063047286, 'recall': 1.0, 'f1': 0.27752639517345395}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.0453987591811596 ; mAP relaxed = 0.0453987591811596\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test_baseline('roberta-large', device, loss, df_val, df_test, val_kpm_data, test_kpm_data, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ֿ** loading task data:\n",
      "\n",
      "ֿ** loading task data:\n",
      "\n",
      "ֿ** loading task data:\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "df_train, df_val, df_test = data_handler.load(path=\"../dataset/\", filename_train=\"train.csv\", filename_test=\"test.csv\", filename_dev=\"dev.csv\", sep_char='#')\n",
    "\n",
    "train_kpm_data = load_kpm_data(\"../dataset/\", subset=\"train\")\n",
    "val_kpm_data = load_kpm_data(\"../dataset/\", subset=\"dev\")\n",
    "test_kpm_data = load_kpm_data(\"../dataset/\", subset=\"test\")\n",
    "\n",
    "# Concatenate topics and keypoints, as stated in the paper\n",
    "df_train = data_handler.concatenate_topics(df_train)\n",
    "df_val = data_handler.concatenate_topics(df_val)\n",
    "df_test = data_handler.concatenate_topics(df_test)\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "loss = torch.nn.MSELoss()\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model(config, df_train, df_val, df_test, max_length, loss, metrics, train_kpm_data, val_kpm_data, test_kpm_data, device, save_model=\"\"):\n",
    "    \"\"\" Train model and evaluate it on\n",
    "    Validation and Test sets, computing\n",
    "    the metrics for each dataset\n",
    "    Parameters\n",
    "    ----------\n",
    "    config: dict\n",
    "        contains parameters and \n",
    "        hyper-parameters useful to train\n",
    "        the model\n",
    "    df_train: pd.DataFrame\n",
    "        Training data\n",
    "    df_val: pd.DataFrame\n",
    "        Validation Data\n",
    "    df_test: pd.DataFrame\n",
    "        Test Data\n",
    "    max_length: int\n",
    "        Max number of tokens\n",
    "    loss: function\n",
    "        function which computes model's loss\n",
    "    metrics: array-like\n",
    "        array of strings containing metrics\n",
    "        to compute\n",
    "    train_kpm_data: tuple\n",
    "        Training data from challenge\n",
    "    val_kpm_data: tuple\n",
    "        Validation data from challenge\n",
    "    test_kpm_data: tuple\n",
    "        Test data from challenge\n",
    "    device: torch device\n",
    "        Selected device on which to perform the grid search \n",
    "        (usually a GPU)\n",
    "    save_model: string default=\"\"\n",
    "        if the string is not empty the model will\n",
    "        be saved to the path contained in the string,\n",
    "        otherwise it won't be saved\n",
    "    Returns\n",
    "    -------\n",
    "    train_challenge_metrics: array-like\n",
    "        Scores on the Training data of the challenge metrics \n",
    "    val_challenge_metrics: tuple\n",
    "        Scores on the Validation data of the challenge metrics \n",
    "    test_challenge_metrics: tuple\n",
    "        Scores on the Test data of the challenge metrics \n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the model's tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['model_type'], do_lower_case=True)\n",
    "\n",
    "    #Tokenize data\n",
    "    columns_list = ['argument', 'key_points', 'label']\n",
    "    tokenized_tr = data_handler.tokenize_df(df_train[columns_list], tokenizer, max_length=max_length)\n",
    "    tokenized_val = data_handler.tokenize_df(df_val[columns_list], tokenizer, max_length=max_length)\n",
    "    tokenized_test = data_handler.tokenize_df(df_test[columns_list], tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(tokenized_tr, batch_size = config['batch_size'], pin_memory=True)\n",
    "    val_loader = DataLoader(tokenized_val, pin_memory=True)\n",
    "    test_loader = DataLoader(tokenized_test, pin_memory=True)\n",
    "\n",
    "    # Create model and move it to the desired device \n",
    "    model = SiameseNetwork(model_type=AutoModel.from_pretrained(config['model_type']))\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    total_steps = len(train_loader) * config['epochs']\n",
    "    \n",
    "    # Create optimizer and scheduler with the desired hyper-parameters\n",
    "    if config['optimizer'] == 'adamW':\n",
    "        optimizer= torch.optim.AdamW(model.parameters(),\n",
    "                  lr = config['lr'], \n",
    "                  eps = config['eps'],\n",
    "                  weight_decay = config['weight_decay'])\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                        num_warmup_steps = config['warmup_steps'],\n",
    "                                        num_training_steps = total_steps)\n",
    "    \n",
    "    \n",
    "    print(\"Starting Training!\")\n",
    "    # Train best model\n",
    "    show_time()\n",
    "    train_res = train(model, device, train_loader, loss, optimizer, config['epochs'], scheduler, verbose=False)\n",
    "    print(\"Training ended!\")\n",
    "    show_time()\n",
    "    \n",
    "    # Compute metrics for each epoch\n",
    "    train_metrics = [0] * config['epochs']\n",
    "    train_challenge_metrics = [0] * config['epochs']\n",
    "\n",
    "    for i in range(config['epochs']):\n",
    "        train_metrics[i] = compute_metrics(train_res['predicted'], train_res['labels'], metrics)\n",
    "        print(f\"Epoch {i+1}/{config['epochs']} results:\\n- Train Metrics: {train_metrics[i]}\\n- Train Challenge Metrics: \")\n",
    "        train_challenge_metrics[i] = extract_challenge_metrics(train_res['predicted'], train_kpm_data[2], train_kpm_data[0], train_kpm_data[1])\n",
    "\n",
    "    # Validate model\n",
    "    model.eval()\n",
    "    val_res = test(model, device, val_loader, loss)\n",
    "    val_metrics = compute_metrics(val_res['predicted'].T, val_res['labels'].T, metrics)\n",
    "    print(f\"Validation results {config['model_type']}:\")\n",
    "    print(val_metrics)\n",
    "\n",
    "    val_challenge_metrics = extract_challenge_metrics(val_res['predicted'].T, val_kpm_data[2], val_kpm_data[0], val_kpm_data[1])\n",
    "    print(val_challenge_metrics)\n",
    "    \n",
    "    # Test model\n",
    "    model.eval()\n",
    "    test_res = test(model, device, test_loader, loss)\n",
    "\n",
    "    test_metrics = compute_metrics(test_res['predicted'].T, test_res['labels'].T, metrics)\n",
    "    print(f\"Test results with model {config['model_type']}:\")\n",
    "    print(test_metrics)\n",
    "\n",
    "    test_challenge_metrics = extract_challenge_metrics(test_res['predicted'].T, test_kpm_data[2], test_kpm_data[0], test_kpm_data[1])\n",
    "    print(test_challenge_metrics)\n",
    "    \n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), save_model)\n",
    "    \n",
    "    return train_challenge_metrics, val_challenge_metrics, test_challenge_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_time():\n",
    "    \"\"\" Displays current time\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_var(arr, set_name):\n",
    "    \"\"\" Compute and print mean and variance of the computed scores\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: array-like\n",
    "        array containing the scores\n",
    "    set_name: string\n",
    "        name of set of data\n",
    "    \"\"\"\n",
    "    arr = np.array(arr)\n",
    "    # Array of single values to compute mean and variance on\n",
    "    vals = []\n",
    "    # Extract values of elements in the array correctly, depending on their shape\n",
    "    if len(arr.shape) == 3:\n",
    "        for i in range(len(arr)):\n",
    "            vals.append(arr[i][0][0])\n",
    "    else:\n",
    "        for i in range(len(arr)):\n",
    "            vals.append(arr[i][0])\n",
    "\n",
    "    vals = np.array(vals)\n",
    "    print(f\"{set_name} Mean: {vals.mean()} and Variance: {vals.var()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta-Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best config of hyper-parameters\n",
    "config = {}\n",
    "config['model_type'] = 'roberta-large'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 6e-6\n",
    "config['eps'] = 1e-8\n",
    "config['weight_decay'] = 1e-2\n",
    "config['warmup_steps'] = 0\n",
    "config['batch_size'] = 8\n",
    "config['optimizer'] = 'adamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 22:17:26\n",
      "Training ended!\n",
      "Current Time = 22:36:04\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8995880785073903, 'precision': 0.8234772324068599, 'recall': 0.653755868544601, 'f1': 0.7288667887987438}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7927716645759911 ; mAP relaxed = 0.7927716645759911\n",
      "Validation results roberta-large:\n",
      "{'accuracy': 0.8525159051474841, 'precision': 0.6565934065934066, 'recall': 0.6476964769647696, 'f1': 0.6521145975443383}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7937510676375459 ; mAP relaxed = 0.7937510676375459\n",
      "(0.7937510676375459, 0.7937510676375459)\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.7189141856392294, 'precision': 0.34652725914861837, 'recall': 0.8405797101449275, 'f1': 0.4907456372289794}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6953469539396201 ; mAP relaxed = 0.6953469539396201\n",
      "(0.6953469539396201, 0.6953469539396201)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 22:41:17\n",
      "Training ended!\n",
      "Current Time = 22:59:57\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8954204022292221, 'precision': 0.8124256837098692, 'recall': 0.6415492957746479, 'f1': 0.7169464847848899}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7723323801350089 ; mAP relaxed = 0.7723323801350089\n",
      "Validation results roberta-large:\n",
      "{'accuracy': 0.8721804511278195, 'precision': 0.7176470588235294, 'recall': 0.6612466124661247, 'f1': 0.6882933709449929}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.8017381088936288 ; mAP relaxed = 0.8017381088936288\n",
      "(0.8017381088936288, 0.8017381088936288)\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.7965557501459428, 'precision': 0.4298160696999032, 'recall': 0.8043478260869565, 'f1': 0.5602523659305995}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7978766740951682 ; mAP relaxed = 0.7978766740951682\n",
      "(0.7978766740951682, 0.7978766740951682)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 23:05:23\n",
      "Training ended!\n",
      "Current Time = 23:24:01\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8958565543978677, 'precision': 0.80709921443119, 'recall': 0.6511737089201878, 'f1': 0.7208003118097961}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7814010489066355 ; mAP relaxed = 0.7814010489066355\n",
      "Validation results roberta-large:\n",
      "{'accuracy': 0.8689994216310005, 'precision': 0.699859747545582, 'recall': 0.6761517615176151, 'f1': 0.687801516195727}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.8143255401800926 ; mAP relaxed = 0.8143255401800926\n",
      "(0.8143255401800926, 0.8143255401800926)\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.8289550496205488, 'precision': 0.4819915254237288, 'recall': 0.8242753623188406, 'f1': 0.6082887700534759}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.8599426769174622 ; mAP relaxed = 0.8599426769174622\n",
      "(0.8599426769174622, 0.8599426769174622)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 23:29:16\n",
      "Training ended!\n",
      "Current Time = 23:47:55\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.894935788708505, 'precision': 0.8111243307555027, 'recall': 0.6401408450704226, 'f1': 0.7155602204145894}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7742477140948688 ; mAP relaxed = 0.7742477140948688\n",
      "Validation results roberta-large:\n",
      "{'accuracy': 0.8765182186234818, 'precision': 0.7345399698340875, 'recall': 0.6598915989159891, 'f1': 0.6952177016416845}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.8156667166049376 ; mAP relaxed = 0.8156667166049376\n",
      "(0.8156667166049376, 0.8156667166049376)\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.822533566841798, 'precision': 0.46963123644251625, 'recall': 0.7844202898550725, 'f1': 0.5875169606512891}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7351702272042945 ; mAP relaxed = 0.7351702272042945\n",
      "(0.7351702272042945, 0.7351702272042945)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 23:53:19\n",
      "Training ended!\n",
      "Current Time = 00:11:57\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8995880785073903, 'precision': 0.828134373125375, 'recall': 0.6481220657276995, 'f1': 0.727153015538583}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7921442889527963 ; mAP relaxed = 0.7921442889527963\n",
      "Validation results roberta-large:\n",
      "{'accuracy': 0.8658183921341817, 'precision': 0.686141304347826, 'recall': 0.6842818428184282, 'f1': 0.6852103120759837}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.8104217379018902 ; mAP relaxed = 0.8104217379018902\n",
      "(0.8104217379018902, 0.8104217379018902)\n",
      "Test results with model roberta-large:\n",
      "{'accuracy': 0.7775831873905429, 'precision': 0.40625, 'recall': 0.8242753623188406, 'f1': 0.5442583732057417}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7951464153900786 ; mAP relaxed = 0.7951464153900786\n",
      "(0.7951464153900786, 0.7951464153900786)\n"
     ]
    }
   ],
   "source": [
    "tr_metrics = []; val_metrics = []; test_metrics = [];\n",
    "\n",
    "for i in range(5):\n",
    "    tr, val, ts = train_best_model(config, df_train, df_val, df_test, max_length, loss, metrics, train_kpm_data, val_kpm_data, test_kpm_data, device)\n",
    "    tr_metrics.append(tr)\n",
    "    val_metrics.append(val)\n",
    "    test_metrics.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.7825794193330602 and Variance: 7.423525505979528e-05\n",
      "Validation Mean: 0.807180634243619 and Variance: 6.870847380400754e-05\n",
      "Test Mean: 0.7647013518721679 and Variance: 0.003345143832373689\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics, set_name)\n",
    "set_name = \"Test\"; compute_mean_var(test_metrics, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best config of hyper-parameters\n",
    "config = {}\n",
    "config['model_type'] = 'roberta-base'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 3e-5\n",
    "config['eps'] = 1e-6\n",
    "config['weight_decay'] = 0\n",
    "config['warmup_steps'] = 0\n",
    "config['batch_size'] = 16\n",
    "config['optimizer'] = 'adamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 02:50:45\n",
      "Training ended!\n",
      "Current Time = 02:55:27\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8925127211049189, 'precision': 0.8001175778953556, 'recall': 0.6389671361502347, 'f1': 0.7105194466196814}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7598303888231116 ; mAP relaxed = 0.7598303888231116\n",
      "Validation results roberta-base:\n",
      "{'accuracy': 0.8412377096587623, 'precision': 0.6412556053811659, 'recall': 0.5813008130081301, 'f1': 0.6098081023454157}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7617557141746133 ; mAP relaxed = 0.7617557141746133\n",
      "(0.7617557141746133, 0.7617557141746133)\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.8257443082311734, 'precision': 0.4721189591078067, 'recall': 0.6902173913043478, 'f1': 0.5607064017660045}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6849173469967372 ; mAP relaxed = 0.6849173469967372\n",
      "(0.6849173469967372, 0.6849173469967372)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 02:58:15\n",
      "Training ended!\n",
      "Current Time = 03:02:57\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8873273564332445, 'precision': 0.7868366439371479, 'recall': 0.6230046948356808, 'f1': 0.6954015459190358}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7558634668044911 ; mAP relaxed = 0.7558634668044911\n",
      "Validation results roberta-base:\n",
      "{'accuracy': 0.8504916136495084, 'precision': 0.6599131693198264, 'recall': 0.6178861788617886, 'f1': 0.6382085374387684}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7532931058191165 ; mAP relaxed = 0.7532931058191165\n",
      "(0.7532931058191165, 0.7532931058191165)\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.826328079392878, 'precision': 0.4736196319018405, 'recall': 0.6992753623188406, 'f1': 0.5647403072421361}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6793356337207017 ; mAP relaxed = 0.6793356337207017\n",
      "(0.6793356337207017, 0.6793356337207017)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 03:05:50\n",
      "Training ended!\n",
      "Current Time = 03:10:32\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8877150472498183, 'precision': 0.7818392805337975, 'recall': 0.6326291079812206, 'f1': 0.6993642143505903}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7530316342929012 ; mAP relaxed = 0.7530316342929012\n",
      "Validation results roberta-base:\n",
      "{'accuracy': 0.8062463851937536, 'precision': 0.5398126463700235, 'recall': 0.6246612466124661, 'f1': 0.5791457286432161}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6925447979408853 ; mAP relaxed = 0.6925447979408853\n",
      "(0.6925447979408853, 0.6925447979408853)\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.805312317571512, 'precision': 0.4385026737967914, 'recall': 0.7427536231884058, 'f1': 0.5514458641560188}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7522375168392447 ; mAP relaxed = 0.7522375168392447\n",
      "(0.7522375168392447, 0.7522375168392447)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 03:13:23\n",
      "Training ended!\n",
      "Current Time = 03:18:05\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8839350617882239, 'precision': 0.7782751417487317, 'recall': 0.612206572769953, 'f1': 0.6853238733412166}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7501870158940754 ; mAP relaxed = 0.7501870158940754\n",
      "Validation results roberta-base:\n",
      "{'accuracy': 0.7891844997108155, 'precision': 0.5049833887043189, 'recall': 0.6178861788617886, 'f1': 0.5557586837294333}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7091879130920542 ; mAP relaxed = 0.7091879130920542\n",
      "(0.7091879130920542, 0.7091879130920542)\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.7743724460011675, 'precision': 0.3968253968253968, 'recall': 0.769927536231884, 'f1': 0.5237215033887862}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7074690838788946 ; mAP relaxed = 0.7074690838788946\n",
      "(0.7074690838788946, 0.7074690838788946)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 03:21:04\n",
      "Training ended!\n",
      "Current Time = 03:25:46\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8908165737824085, 'precision': 0.8028976758225174, 'recall': 0.6244131455399061, 'f1': 0.7024957084378713}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7666591769542629 ; mAP relaxed = 0.7666591769542629\n",
      "Validation results roberta-base:\n",
      "{'accuracy': 0.8522267206477733, 'precision': 0.6765163297045101, 'recall': 0.5894308943089431, 'f1': 0.6299782766111515}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7530979935665372 ; mAP relaxed = 0.7530979935665372\n",
      "(0.7530979935665372, 0.7530979935665372)\n",
      "Test results with model roberta-base:\n",
      "{'accuracy': 0.808231173380035, 'precision': 0.4418604651162791, 'recall': 0.7228260869565217, 'f1': 0.5484536082474227}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6834034761849064 ; mAP relaxed = 0.6834034761849064\n",
      "(0.6834034761849064, 0.6834034761849064)\n"
     ]
    }
   ],
   "source": [
    "tr_metrics_roberta = []; val_metrics_roberta = []; test_metrics_roberta = [];\n",
    "\n",
    "for i in range(5):\n",
    "    tr, val, ts = train_best_model(config, df_train, df_val, df_test, max_length, loss, metrics, train_kpm_data, val_kpm_data, test_kpm_data, device)\n",
    "    tr_metrics_roberta.append(tr)\n",
    "    val_metrics_roberta.append(val)\n",
    "    test_metrics_roberta.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.7571143365537685 and Variance: 3.294036452069443e-05\n",
      "Validation Mean: 0.7339759049186412 and Variance: 0.0007683014982765409\n",
      "Test Mean: 0.7014726115240969 and Variance: 0.000740729902820524\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics_roberta, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics_roberta, set_name)\n",
    "set_name = \"Test\"; compute_mean_var(test_metrics_roberta, set_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best config of hyper-parameters\n",
    "config = {}\n",
    "config['model_type'] = 'bert-base-uncased'\n",
    "config['epochs'] = 1\n",
    "config['lr'] = 3e-5\n",
    "config['eps'] = 1e-6\n",
    "config['weight_decay'] = 1e-2\n",
    "config['warmup_steps'] = 0\n",
    "config['batch_size'] = 8\n",
    "config['optimizer'] = 'adamW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 09:07:26\n",
      "Training ended!\n",
      "Current Time = 09:13:17\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8896050399806155, 'precision': 0.7972405518896221, 'recall': 0.6239436619718309, 'f1': 0.7000263365815117}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7378281893305237 ; mAP relaxed = 0.7378281893305237\n",
      "Validation results bert-base-uncased:\n",
      "{'accuracy': 0.772700983227299, 'precision': 0.474025974025974, 'recall': 0.5934959349593496, 'f1': 0.5270758122743683}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.650537089625474 ; mAP relaxed = 0.650537089625474\n",
      "(0.650537089625474, 0.650537089625474)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.7705779334500875, 'precision': 0.38392857142857145, 'recall': 0.7010869565217391, 'f1': 0.4961538461538461}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6620536815148249 ; mAP relaxed = 0.6620536815148249\n",
      "(0.6620536815148249, 0.6620536815148249)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 09:16:09\n",
      "Training ended!\n",
      "Current Time = 09:22:00\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8881027380663921, 'precision': 0.794802055001511, 'recall': 0.6173708920187794, 'f1': 0.6949398863786498}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7422235518125243 ; mAP relaxed = 0.7422235518125243\n",
      "Validation results bert-base-uncased:\n",
      "{'accuracy': 0.7706766917293233, 'precision': 0.47020585048754066, 'recall': 0.5880758807588076, 'f1': 0.522576760987357}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.667085088276972 ; mAP relaxed = 0.667085088276972\n",
      "(0.667085088276972, 0.667085088276972)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.7848803269118505, 'precision': 0.4053224155578301, 'recall': 0.717391304347826, 'f1': 0.5179856115107915}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7705481278833463 ; mAP relaxed = 0.7705481278833463\n",
      "(0.7705481278833463, 0.7705481278833463)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 09:25:04\n",
      "Training ended!\n",
      "Current Time = 09:31:00\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.887424279137388, 'precision': 0.7928636226186876, 'recall': 0.6154929577464788, 'f1': 0.6930091185410333}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7245120806854372 ; mAP relaxed = 0.7245120806854372\n",
      "Validation results bert-base-uncased:\n",
      "{'accuracy': 0.7755928282244072, 'precision': 0.4791666666666667, 'recall': 0.592140921409214, 'f1': 0.5296969696969698}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6374135515609798 ; mAP relaxed = 0.6374135515609798\n",
      "(0.6374135515609798, 0.6374135515609798)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.8245767659077642, 'precision': 0.4703030303030303, 'recall': 0.7028985507246377, 'f1': 0.5635439360929557}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.684497479862793 ; mAP relaxed = 0.684497479862793\n",
      "(0.684497479862793, 0.684497479862793)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 09:34:21\n",
      "Training ended!\n",
      "Current Time = 09:40:12\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8867942815604556, 'precision': 0.7856294536817102, 'recall': 0.6211267605633802, 'f1': 0.6937598321971683}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7372847892301083 ; mAP relaxed = 0.7372847892301083\n",
      "Validation results bert-base-uncased:\n",
      "{'accuracy': 0.757085020242915, 'precision': 0.44642857142857145, 'recall': 0.575880758807588, 'f1': 0.5029585798816568}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6537430781764763 ; mAP relaxed = 0.6537430781764763\n",
      "(0.6537430781764763, 0.6537430781764763)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.787215411558669, 'precision': 0.4045307443365696, 'recall': 0.6793478260869565, 'f1': 0.5070993914807304}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6830080396437562 ; mAP relaxed = 0.6830080396437562\n",
      "(0.6830080396437562, 0.6830080396437562)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training!\n",
      "Current Time = 09:43:27\n",
      "Training ended!\n",
      "Current Time = 09:49:19\n",
      "Epoch 1/1 results:\n",
      "- Train Metrics: {'accuracy': 0.8856796704628059, 'precision': 0.7898749618786215, 'recall': 0.607981220657277, 'f1': 0.6870937790157846}\n",
      "- Train Challenge Metrics: \n",
      "\tloaded predictions for 5583 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.7299253339745607 ; mAP relaxed = 0.7299253339745607\n",
      "Validation results bert-base-uncased:\n",
      "{'accuracy': 0.7729901677270098, 'precision': 0.47368421052631576, 'recall': 0.573170731707317, 'f1': 0.5187001839362354}\n",
      "\tloaded predictions for 932 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6517818415070075 ; mAP relaxed = 0.6517818415070075\n",
      "(0.6517818415070075, 0.6517818415070075)\n",
      "Test results with model bert-base-uncased:\n",
      "{'accuracy': 0.7603619381202569, 'precision': 0.37178265014299333, 'recall': 0.7065217391304348, 'f1': 0.4871955028107433}\n",
      "\tloaded predictions for 723 arguments\n",
      "\n",
      "** running evalution:\n",
      "mAP strict= 0.6741351496370575 ; mAP relaxed = 0.6741351496370575\n",
      "(0.6741351496370575, 0.6741351496370575)\n"
     ]
    }
   ],
   "source": [
    "tr_metrics_bert = []; val_metrics_bert = []; test_metrics_bert = [];\n",
    "\n",
    "for i in range(5):\n",
    "    tr, val, ts = train_best_model(config, df_train, df_val, df_test, max_length, loss, metrics, train_kpm_data, val_kpm_data, test_kpm_data, device)\n",
    "    tr_metrics_bert.append(tr)\n",
    "    val_metrics_bert.append(val)\n",
    "    test_metrics_bert.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean: 0.7343547890066308 and Variance: 3.9813163638447315e-05\n",
      "Validation Mean: 0.6521121298293819 and Variance: 8.909750446326312e-05\n",
      "Test Mean: 0.6948484957083556 and Variance: 0.0014964633567478485\n"
     ]
    }
   ],
   "source": [
    "set_name = \"Train\"; compute_mean_var(tr_metrics_bert, set_name)\n",
    "set_name = \"Validation\"; compute_mean_var(val_metrics_bert, set_name)\n",
    "set_name = \"Test\"; compute_mean_var(test_metrics_bert, set_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ede013c901f8a5774d468d6246940287a78a31eaa126b6cb7e1aa2724460e30f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
